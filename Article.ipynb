{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e35509a9-d025-48dc-886d-3316ebc5e675",
   "metadata": {},
   "source": [
    "# Finding clothes with Scrapegraph, Jina Clip v2 and Qdrant Vector Search Engine üëó\n",
    "\n",
    "Hi there üëã Today we're building a small demo to search clothes from [zalando](https://zalando.com/) directly with natural language or images. Our plan of attack is to first scrape them, embed the images using a multimodal model and then store them into a vector search enginge so we can search!\n",
    "\n",
    "Scraping websites is not an easy task, most of them cannot be easily fetched with an http request and require javascript to be loaded. If we try to make a HTTP request to zalando, we'll be blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77b0f02-476b-4ad9-a3bd-95c76e3c95e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.get(\"https://www.zalando.it/jeans-donna\")\n",
    "# we'll get 403\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c8f9e0-e26b-4d74-8b16-b166d57c5a3d",
   "metadata": {},
   "source": [
    "We need something smarter, [scrapegraph](https://scrapegraphai.com/) is a perfect tool for the job. It can bypass website blockers and allow us to define a [pydantic schema](https://docs.pydantic.dev/latest/concepts/models/) to scrape the information we want. It works by loading the website, parsing it and using LLMs to fill our schema with the data within the page.\n",
    "\n",
    "Once we get the data, we need a way to create vectors to store/search. Since we want to work with images and text, we need the heavy guns. [Jina ClipV2](https://jina.ai/news/jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images/) is a wonderful open source model that can represent both images and text as vectors, thus it's a perfect pick for the task.\n",
    "\n",
    "Finally, we need to save our juicy vectors somewhere. [Qdrant](https://qdrant.tech/) is my go-to vector database, you can self host it with [docker](https://hub.docker.com/r/qdrant/qdrant) and it comes with a handy ui. It supports different vector quantization techniques, so we can squeeze a lot of performance!\n",
    "\n",
    "So, to recap. Our plan of attack looks something like:\n",
    "\n",
    "![alt](./images/flow.png)\n",
    "\n",
    "1. Scrape with Scrapegraph\n",
    "2. Embed with Jina ClipV2\n",
    "3. Store with Qdrant\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473bcb5-00d2-4134-8f38-30ca5423ded4",
   "metadata": {},
   "source": [
    "## Setting it up\n",
    "\n",
    "We'll need a bunch of packages. I am using `uv`, so we'll stick with it. You can init your project using\n",
    "\n",
    "```\n",
    "uv init\n",
    "uv add python-dotenv scrapegraph-py==1.24.0 aiofiles sentence-transformers qdrant-client\n",
    "```\n",
    "\n",
    "Or if you prefer `pip`\n",
    "\n",
    "```\n",
    "pip install python-dotenv scrapegraph-py==1.24.0 aiofiles sentence-transformers qdrant-client\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1a98b8-75b9-43cd-a0b6-f6aed29c2be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m161 packages\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m141 packages\u001b[0m \u001b[2min 0.60ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add python-dotenv scrapegraph-py==1.24.0 aiofiles sentence-transformers qdrant-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf92da4-c74e-481b-9c71-08c7a5be2b85",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "First of all, head over to the [scrapegraph dashboard](https://dashboard.scrapegraphai.com/) and get your API key. Create a `.env` file and put it inside\n",
    "\n",
    "```\n",
    "GAI_API_KEY=\"YOUR_API_KEY\"\n",
    "```\n",
    "\n",
    "Then we load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0936f5d4-87c5-466a-a634-d5e9ad5d26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "SGAI_API_KEY = os.getenv(\"SGAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607ec75-8517-4954-addd-656aceab5030",
   "metadata": {},
   "source": [
    "Now, we need to define the data we want. Each article/item on the website looks like:\n",
    "\n",
    "![alt](images/zalando-article.png)\n",
    "\n",
    "We have a brand, name, description, price, image, review, etc.\n",
    "\n",
    "In order to tell scrapegraph what we want to extract, we have to define a couple of pydantic schemas. Since a page contains multiple items, we'll create an `ArticleModel` for the single article, and `ArticlesModel` containing an array of them.\n",
    "\n",
    "We can add `description` to make sure we guide the LLM into extracting the correct info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b48a0a-1f0d-4e90-8c9c-9f233c2683d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "import asyncio\n",
    "\n",
    "\n",
    "class ArticleModel(BaseModel):\n",
    "    name: str = Field(description=\"Name of the article\")\n",
    "    brand: str = Field(description=\"Brand of the article\")\n",
    "    description: str = Field(description=\"Description of the article\")\n",
    "    price: float = Field(description=\"Price of the article\")\n",
    "    review_score: float = Field(description=\"Review score of the article, out of five.\")\n",
    "    url: str = Field(description=\"Article url\")\n",
    "    image_url: Optional[str]= Field(description=\"Article's image url\")\n",
    "\n",
    "\n",
    "class ArticlesModel(BaseModel):\n",
    "    articles: list[ArticleModel] = Field(description=\"Articles on the page, only the ones with price, review and image. Discard the others\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40eeef1-1835-472c-9699-5250d61a674d",
   "metadata": {},
   "source": [
    "Now, the fun part. We'll store our scraped data locally into a `.jsonl` file. We'll also add a `user_prompt` to guide scrapegraph even further. Since the scraping process is heavily I/O bound, we'll use their `AsyncClient` so we can fire a lot of them at once.\n",
    "\n",
    "Let's import everything and define our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ab676c-747c-40b8-8c19-058b5df844ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "# let' use async\n",
    "from scrapegraph_py import AsyncClient\n",
    "from scrapegraph_py.logger import sgai_logger\n",
    "sgai_logger.set_logging(level=\"INFO\")\n",
    "\n",
    "# let's use async to write to the file as well\n",
    "import aiofiles\n",
    "import json\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "JSON_PATH = \"scrape.jsonl\"\n",
    "# how much scraping request to fire at one\n",
    "BATCH_SIZE = 8\n",
    "# how many pages per category\n",
    "MAX_PAGES = 100\n",
    "\n",
    "# the user prompt to send to scrapegraph along the pydantic schemas\n",
    "\n",
    "user_prompt = \"\"\"Extract ONLY the articles in the page with price, review and image url. Discard all the others.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae0c6d-ba43-44ae-b0f4-702068991ce9",
   "metadata": {},
   "source": [
    "To start scraping, we can use the [smartscraper](https://docs.scrapegraphai.com/services/smartscraper) method. Let's quickly see it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3466880-0c6b-4691-9b43-10c6898605cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí¨ 2025-10-08 10:23:24,101 üîë Initializing AsyncClient\n",
      "üí¨ 2025-10-08 10:23:24,101 ‚úÖ AsyncClient initialized successfully\n",
      "üí¨ 2025-10-08 10:23:24,101 üîç Starting smartscraper request\n",
      "üí¨ 2025-10-08 10:23:24,104 üöÄ Making POST request to https://api.scrapegraphai.com/v1/smartscraper (Attempt 1/3)\n",
      "üí¨ 2025-10-08 10:23:34,194 ‚úÖ Request completed successfully: POST https://api.scrapegraphai.com/v1/smartscraper\n",
      "üí¨ 2025-10-08 10:23:34,196 ‚ú® Smartscraper request completed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'Calvin Klein Jeans MID RISE - Jeans a sigaretta - indigo channel',\n",
       "  'brand': 'Calvin Klein Jeans',\n",
       "  'description': 'No content available',\n",
       "  'price': 54.99,\n",
       "  'review_score': 0,\n",
       "  'url': 'https://www.zalando.it/calvin-klein-jeans-mid-rise-jeans-a-sigaretta-indigo-channel-c1821n0wb-k11.html',\n",
       "  'image_url': 'https://img01.ztat.net/article/spp-media-p1/391e37f99e42468193efe13676cb98f4/7f2e068eb2a24d3aa5edadce0e9fd461.jpg?imwidth=300'},\n",
       " {'name': 'GAP BAGGY DYLAN - Wide Leg - light indigo',\n",
       "  'brand': 'GAP',\n",
       "  'description': 'No content available',\n",
       "  'price': 42.49,\n",
       "  'review_score': 0,\n",
       "  'url': 'https://www.zalando.it/gap-baggy-dylan-jeans-baggy-light-indigo-gp021n0ih-k11.html',\n",
       "  'image_url': 'https://img01.ztat.net/article/spp-media-p1/0a09f06a933c4714bb81369f858c9cde/8c619d57599f43ee9577b67e5c8ee170.jpg?imwidth=300'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining our client\n",
    "client = AsyncClient()\n",
    "# get our zalando link for women's jeans - sorry I am Italian xD\n",
    "url = \"https://www.zalando.it/jeans-donna/\"\n",
    "# get the response\n",
    "response = await client.smartscraper(\n",
    "                website_url=url,\n",
    "                user_prompt=user_prompt,\n",
    "                output_schema=ArticlesModel)\n",
    "\n",
    "response[\"result\"][\"articles\"][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6cda2-6419-446f-afbc-109086adbe80",
   "metadata": {},
   "source": [
    "Okay, let's make our code bulletproof. We need a function to save our data to disk as JSONL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d39735-f70b-411c-8236-9052551bfb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def save(result: dict):\n",
    "    async with aiofiles.open(JSON_PATH, 'a') as f:\n",
    "        await f.write(json.dumps(result) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d719202-e03a-4716-aed2-e4a59d0b0c35",
   "metadata": {},
   "source": [
    "Let's then call `smartscraper`, passing the `client` and the `url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c885b7f-984e-4224-bacd-4c7fe35d3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_and_save(client: AsyncClient, url: str): \n",
    "    start = perf_counter()\n",
    "    sgai_logger.info(f\"Scraping url={url}\")\n",
    "    response = await client.smartscraper(\n",
    "                website_url=url,\n",
    "                user_prompt=user_prompt,\n",
    "                output_schema=ArticlesModel)\n",
    "    await save(response)\n",
    "    sgai_logger.info(f\"Tooked {perf_counter() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d9fed8-1c9d-456f-a71d-f0d1cd44b803",
   "metadata": {},
   "source": [
    "Finally, putting it all together. We'll scrape women's jeans and t-shirt tops. We'll check first if `JSON_PATH` exists, and if so we'll assume we had already scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285cdbb5-fa49-4fb2-afbc-3fb2f1b8f28e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "    get_urls = [\n",
    "        lambda page: f\"https://www.zalando.it/jeans-donna/?p={page}\",\n",
    "        lambda page: f\"https://www.zalando.it/t-shirt-top-donna/?p={page}\"\n",
    "    ]\n",
    "\n",
    "    should_scrape = not os.path.exists(JSON_PATH)\n",
    "    if not should_scrape:\n",
    "        sgai_logger.info(f\"jsonl file exists, assuming we had scrape already. Quitting ...\")\n",
    "        return\n",
    "    async with AsyncClient() as client:\n",
    "        for get_url in get_urls:\n",
    "            for i in range(1, MAX_PAGES + 1, BATCH_SIZE):\n",
    "                pages = list(range(i, min(i + BATCH_SIZE, MAX_PAGES + 1)))\n",
    "                tasks = [scrape_and_save(client, get_url(page)) for page in pages]\n",
    "                await asyncio.gather(*tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1411e2a-3a1e-41a5-97e4-6c96a935f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí¨ 2025-10-08 10:23:34,214 jsonl file exists, assuming we had scrape already. Quitting ...\n"
     ]
    }
   ],
   "source": [
    "# we'll take some minutes\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42036a3-1a3b-4b9c-b59d-1c39ac55ccee",
   "metadata": {},
   "source": [
    "And then you have it, each line is a page scraped!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56c510aa-b45b-4629-a282-b49775c1c7d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'PULL&BEAR BAGGY - Jeans baggy - white',\n",
       " 'brand': 'PULL&BEAR',\n",
       " 'description': 'Cropped top bianco senza maniche abbinato a pantaloni bianchi a gamba larga, con tasche frontali e chiusura a bottone. Sandali piatti marroni con borchie.',\n",
       " 'price': 35.99,\n",
       " 'review_score': 0,\n",
       " 'url': 'https://www.zalando.it/pullandbear-jeans-bootcut-white-puc21n0rs-a11.html',\n",
       " 'image_url': 'https://img01.ztat.net/article/spp-media-p1/ff33dd220e7c4827ba1b8be760e6de7c/b9ca1dcb64b04fa98b0e0d5fa38fff14.jpg?imwidth=300'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(JSON_PATH, \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        data = json.loads(line)\n",
    "        break\n",
    "\n",
    "data[\"result\"][\"articles\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a1618-2654-4715-8ad3-c0c9f2fbe4ca",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "The heavy part is done, now we need to embed each image. We'll convert the images into numerical vectors so we can perform similarity searches and find visually similar products. Recall, our `pydantic` model has an `.image_url` field that holds the link to the image for an article on Zalando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0405c17-1b0a-4b23-a7b4-954de62051d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://img01.ztat.net/article/spp-media-p1/ff33dd220e7c4827ba1b8be760e6de7c/b9ca1dcb64b04fa98b0e0d5fa38fff14.jpg?imwidth=300'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"result\"][\"articles\"][0][\"image_url\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b160d8e-d24f-46fb-97d5-2bec4188f1d7",
   "metadata": {},
   "source": [
    "Let's do some good programming, limiting the amount of data we have in memory each time. We'll batch process the articles, so we can load one line of the JSONL at a time. This can be done in Python with a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4421658-086f-4c30-afb1-afbd26e71b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_from_disk():\n",
    "    with open(JSON_PATH, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            data = json.loads(line)\n",
    "            yield data[\"result\"][\"articles\"]\n",
    "\n",
    "articles_gen = get_articles_from_disk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a10272-b72e-4bb6-a7f4-d1dd0ef3562c",
   "metadata": {},
   "source": [
    "We'll use the wonderful [ClipV2 model made by Jina](https://jina.ai/news/jina-clip-v2-multilingual-multimodal-embeddings-for-text-and-images/) to create vectors for our images. The model has matryoshka representation, allowing (quoting from their blog post) to \"truncate the output dimensions of both text and image embeddings from 1024 down to 64, reducing storage and processing overhead while maintaining strong performance.\" We'll use 512 dimensions and use the model with [sentence_transformers](https://sbert.net/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c0269f-7dc0-4cb5-9c9e-098c2938bc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775c893e09d2425d9fcfc9c5c57aa97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/273 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f6f63bede84cb2b9a07f48599b694f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dabda2e06914a8eb1b24f63af252544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d290725cf5a4493eafc05ee84bae63df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "custom_st.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-clip-v2:\n",
      "- custom_st.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95372612667c4d27acfda89b6f22aea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af302c2546b42b9946b8d755608f4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_clip.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-clip-implementation:\n",
      "- configuration_clip.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5014c1348841098aefe91230fef409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_clip.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3dc5268ad24748b14917d7a9f6d1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rope_embeddings.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-clip-implementation:\n",
      "- rope_embeddings.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dcacfeae084fa9a84cbf9e025a8432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_model.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-clip-implementation:\n",
      "- hf_model.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4c2a088d834cefbaa4b2ce97c6bb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eva_model.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-clip-implementation:\n",
      "- eva_model.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79185567465c444da3d57dc27c7d49ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transform.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-clip-implementation:\n",
      "- transform.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-clip-implementation:\n",
      "- modeling_clip.py\n",
      "- rope_embeddings.py\n",
      "- hf_model.py\n",
      "- eva_model.py\n",
      "- transform.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12121322a87f43bfb8258bf981fc6848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.73G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/FRANCESCO.ZUPPICHINI/.cache/huggingface/modules/transformers_modules/jinaai/jina-clip-implementation/39e6a55ae971b59bea6e44675d237c99762e7ee2/modeling_clip.py:137: UserWarning: Flash attention requires CUDA, disabling\n",
      "  warnings.warn('Flash attention requires CUDA, disabling')\n",
      "/Users/FRANCESCO.ZUPPICHINI/.cache/huggingface/modules/transformers_modules/jinaai/jina-clip-implementation/39e6a55ae971b59bea6e44675d237c99762e7ee2/modeling_clip.py:172: UserWarning: xFormers requires CUDA, disabling\n",
      "  warnings.warn('xFormers requires CUDA, disabling')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cc9bdba69841a1a33b48139b2a886a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d90bc4e5a144ed9cd1963572c27611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_xlm_roberta.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- configuration_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5764a46948438e8b9c7996b4f9366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_lora.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e6de90df4949a39c4bfd284561f1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_xlm_roberta.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdd7dc6268f4b058720ece0f9e89e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mha.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9d2577ec35485383f79eb2cb5a9126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rotary.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mha.py\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda4bc4158074f97a7b07e373cd9c28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlp.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mlp.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a34674137d4b7791886777bb95e864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "block.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d545d41920e46f0a7f792c26e46edd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "stochastic_depth.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- block.py\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a8aa3090a04a1ba5ff31a6242a67db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58370d28d4ea4374b672ec91d49bc901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xlm_padding.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_xlm_roberta.py\n",
      "- mha.py\n",
      "- mlp.py\n",
      "- block.py\n",
      "- embedding.py\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_lora.py\n",
      "- modeling_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3526c5893dd84a9ba7804507bc38508a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39144266f804ddfb43b71867aa2f2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a78ad20e68f437f96a1a64ce25ab2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ab202dff30485ebc98324f671e48dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651ef76139d446f0b89e3342393d3e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1a062b9cb64b6fa757628d4e0bfd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5366fabde3340e19fb9bc821c6ff144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/584 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1124cab21ec4e99a9c04d6801b15bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing_clip.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-clip-implementation:\n",
      "- processing_clip.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "EMBEDDING_SIZE = 512\n",
    "\n",
    "# initialize the model - will take some time to download it\n",
    "model = SentenceTransformer(\n",
    "    \"jinaai/jina-clip-v2\", trust_remote_code=True, truncate_dim=EMBEDDING_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff572120-4778-404f-836b-478912e0283d",
   "metadata": {},
   "source": [
    "Then, we can just pass an image URL to get the embeddings. We also normalize them since we will use cosine similarity to perform search later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03c8a7ce-5b1f-454f-95d6-e3aca82d1969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12898703,  0.13965721, -0.13102548,  0.09683744, -0.02695999,\n",
       "        0.04831071, -0.15391393,  0.01224686, -0.10350402,  0.05697947],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings = model.encode(data[\"result\"][\"articles\"][0][\"image_url\"], normalize_embeddings=True)\n",
    "\n",
    "image_embeddings[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4416d70-041d-4de5-b76a-fb83bb1a7f1e",
   "metadata": {},
   "source": [
    "## Storing\n",
    "\n",
    "Now we need somewhere to store them. Qdrant is a perfect solution, and we'll run it locally with [Docker](https://docs.docker.com/engine/install/) and [Docker Compose](https://docs.docker.com/compose/).\n",
    "\n",
    "Assuming you have it on your system, we create a `docker-compose.yml` file.\n",
    "\n",
    "```yml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:latest\n",
    "    ports:\n",
    "      - \"6333:6333\"\n",
    "      - \"6334:6334\"\n",
    "    volumes:\n",
    "      - ./qdrant_storage:/qdrant/storage:z\n",
    "\n",
    "```\n",
    "\n",
    "Then, simply\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "This will spin up Qdrant, which also comes with a very nice UI accessible at `http://localhost:6333/dashboard#/collections` where you can see your data.\n",
    "\n",
    "### Initialize the database\n",
    "\n",
    "We need to create a collection. We'll also use quantization to speed things up and save storage. You can read more in the [Qdrant documentation](https://qdrant.tech/documentation/guides/quantization/) about this feature. We'll use `cosine` similarity for search and keep the quantized vectors in RAM to speed things up as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26e6854-916a-4e27-bb2c-b1c5cedadbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10d05d010>\n",
      "Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x10d0319d0>, 12896.416191291)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x10d05cc20>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothes created!\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import numpy as np\n",
    "\n",
    "QDRANT_COLLECTION_NAME = \"clothes\"\n",
    "QDRANT_URL = \"http://localhost:6333\"\n",
    "\n",
    "# defining qdrant client\n",
    "client = QdrantClient(url=QDRANT_URL)\n",
    "\n",
    "# checking if we haven't created the collection already\n",
    "if not client.collection_exists(QDRANT_COLLECTION_NAME):\n",
    "    print(f\"{QDRANT_COLLECTION_NAME} created!\")\n",
    "    client.create_collection(\n",
    "        collection_name=QDRANT_COLLECTION_NAME,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=EMBEDDING_SIZE, distance=models.Distance.COSINE, on_disk=True\n",
    "        ),\n",
    "        quantization_config=models.ScalarQuantization(\n",
    "            scalar=models.ScalarQuantizationConfig(\n",
    "                type=models.ScalarType.INT8,\n",
    "                quantile=0.99,\n",
    "                always_ram=True,\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c52c7e0-81ad-4508-aa57-02af1dfd3f03",
   "metadata": {},
   "source": [
    "We want to process our data in batches to efficiently utilize both the embedding model and the network connection to Qdrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc9fc43f-7233-4778-a5ac-1bdf1932e4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "def embed_articles(data: dict) -> np.array:\n",
    "    image_urls = [el[\"image_url\"] for el in data]\n",
    "    image_embeddings = model.encode(\n",
    "            image_urls, normalize_embeddings=True\n",
    "        )\n",
    "    return image_embeddings       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e478d9-baa7-4283-9069-4d1d602ecb86",
   "metadata": {},
   "source": [
    "### Inserting into the database\n",
    "\n",
    "Then, we can create a function to insert them into the database. We'll also store the dictionary itself by passing it to the `payload` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "083e489e-2940-4fa4-9cbb-f469f7b97676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_articles_in_db(batch: list[dict], embeddings: np.array):\n",
    "    client.upsert(\n",
    "        collection_name=QDRANT_COLLECTION_NAME,\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=vector,\n",
    "                payload=payload\n",
    "            )\n",
    "            for payload, vector in zip(batch, embeddings)\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be76e61-0e99-4a4b-87f6-ec6a8f96c8c8",
   "metadata": {},
   "source": [
    "Putting it all together, we'll check if we have points in the collection; if so, we'll assume we've already run it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46507155-9e40-4559-b190-d89a04c9bcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection=clothes not empty. Exiting ...\n"
     ]
    }
   ],
   "source": [
    "def store_to_vector_db():\n",
    "    shold_insert = client.count(QDRANT_COLLECTION_NAME).count == 0\n",
    "    if not shold_insert: \n",
    "        print(f\"Collection={QDRANT_COLLECTION_NAME} not empty. Exiting ...\")\n",
    "        return\n",
    "    with tqdm(articles_gen, desc=\"Article Collections\", position=0) as pbar_collections:\n",
    "        for articles in pbar_collections:\n",
    "            batches = list(range(0, len(articles), BATCH_SIZE))\n",
    "            with tqdm(batches, desc=\"Processing Batches\", position=1, leave=False) as pbar_batches:\n",
    "                for i in pbar_batches:\n",
    "                    batch = articles[i:i + BATCH_SIZE]\n",
    "                    embeddings = embed_articles(batch)\n",
    "                    insert_articles_in_db(batch, embeddings)\n",
    "\n",
    "store_to_vector_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12e05b8-4df6-4f4b-a282-d5967cf7a884",
   "metadata": {},
   "source": [
    "We can head over the [qdrant ui](http://localhost:6333/dashboard#/collections/clothes) to see the data\n",
    "\n",
    "![alt](images/sgai-qdrant-frontend.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec4e25-be06-42e5-8946-a12c6297b177",
   "metadata": {},
   "source": [
    "It also comes with a very cool dimension reduction tab to explore our embeddings!\n",
    "![alt](images/sgai-qdrant-frontend-embeddings.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf12b32-a7d7-489b-9f3e-9eb8a45e0693",
   "metadata": {},
   "source": [
    "### Searching\n",
    "\n",
    "We can now search ü•≥! With either a text query or an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f52e84-02ba-49f6-a017-66a02568be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/ghlgjhss71l6tm_gvh7nzcv80000gp/T/ipykernel_41659/1688051610.py:8: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  res = client.search(\n"
     ]
    }
   ],
   "source": [
    "query = 'red pants'\n",
    "# call the model to embed the query\n",
    "query_embeddings = model.encode(\n",
    "    query, prompt_name='retrieval.query', normalize_embeddings=True\n",
    "    \n",
    ")  \n",
    "# getting results\n",
    "res = client.search(\n",
    "        collection_name=QDRANT_COLLECTION_NAME,\n",
    "        query_vector=query_embeddings.tolist(),\n",
    "        limit=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007bfe0-b97f-4074-8b68-1a8582a84090",
   "metadata": {},
   "source": [
    "Let's define a function to show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ad8b53e-a0cc-4572-9eca-95130225dfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display:grid;grid-template-columns:repeat(4,1fr);gap:10px;'><img src='https://img01.ztat.net/article/spp-media-p1/14d11c8dc1084fd68dec60fbac92a41c/504c7695a7004dbb810970bb8014d5aa.jpg?imwidth=300' style='width:300px;height:auto;object-fit:cover;border:1px solid #ddd;'><img src='https://img01.ztat.net/article/spp-media-p1/148c48ea5af143c4b7868a21683a9e1e/6fc29d5783b448aebeacab72a89a6e77.jpg?imwidth=300' style='width:300px;height:auto;object-fit:cover;border:1px solid #ddd;'><img src='https://img01.ztat.net/article/spp-media-p1/f203270fbbd845148bb432014aacc3c1/ba0e6318c6a943dea9fa032a702d52ff.jpg?imwidth=300' style='width:300px;height:auto;object-fit:cover;border:1px solid #ddd;'><img src='https://img01.ztat.net/article/spp-media-p1/f7f93ebd0ddd496bb4f1b224a7c4d555/64c63bd0e85a406f9ec2764811438ec4.jpg?imwidth=300' style='width:300px;height:auto;object-fit:cover;border:1px solid #ddd;'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_images(res):\n",
    "    html = \"<div style='display:grid;grid-template-columns:repeat(4,1fr);gap:10px;'>\"\n",
    "    for result in res:\n",
    "        html += f\"<img src='{result.payload['image_url']}' style='width:300px;height:auto;object-fit:cover;border:1px solid #ddd;'>\"\n",
    "    html += \"</div>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "show_images(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6676e3-55d7-46f6-9aa2-5cd605e57c1e",
   "metadata": {},
   "source": [
    "We're seeing mixed results here‚Äîboth red pants and red tops appear in our outputs. The issue stems from how we process the images. Most product photos show nearly full-body shots of the model, so when we have a jeans item, for example, the image captures both the jeans and the upper body. We'll leave it as a take-home exercise for the reader to use a segmentation model to isolate the actual article from the model, crop it, and then embed it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ecb28d-4406-49a7-acfe-177ea1b10944",
   "metadata": {},
   "source": [
    "Since ClipV2 is multimodal, we can also use an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e8a0cc5-532d-46a8-a146-1d09477cf0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/ghlgjhss71l6tm_gvh7nzcv80000gp/T/ipykernel_41659/1374654977.py:9: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  res = client.search(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://d1fufvy4xao6k9.cloudfront.net/images/landings/43/shirts-mob-1.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or using either a pil image or a url\n",
    "from IPython.display import Image, display\n",
    "image_url = \"https://d1fufvy4xao6k9.cloudfront.net/images/landings/43/shirts-mob-1.jpg\"\n",
    "# call the model to embed the query\n",
    "query_embeddings = model.encode(\n",
    "            image_url, normalize_embeddings=True\n",
    "        )\n",
    "# getting results\n",
    "res = client.search(\n",
    "        collection_name=QDRANT_COLLECTION_NAME,\n",
    "        query_vector=query_embeddings.tolist(),\n",
    "        limit=4,\n",
    "    )\n",
    "\n",
    "Image(url=image_url, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6f09ecc-1060-4236-9207-e3f57b4c3477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display:grid;grid-template-columns:repeat(4,1fr);gap:10px;'><img src='https://img01.ztat.net/article/spp-media-p1/13f14ab6cacc4f33aea6cfadb0fac207/7aef5c18accf478d860a3331103b73f6.jpg?imwidth=300' style='width:300px;height:auto;object-fit:cover;border:1px solid #ddd;'><img src='https://img01.ztat.net/article/spp-media-p1/7677dca00ac64142bbd7f40a123fa9f1/5e505f360e094ad89fe394ac376261a8.jpg?imwidth=300' style='width:300px;height:auto;object-fit:cover;border:1px solid #ddd;'><img src='https://img01.ztat.net/article/spp-media-p1/d1d3b10d972747edb8f0820108654c09/c48761ba8f78492cb1e44d629c0532b9.jpg?imwidth=300' style='width:300px;height:auto;object-fit:cover;border:1px solid #ddd;'><img src='https://img01.ztat.net/article/spp-media-p1/62cfd75b7e634ec2809e0ab7f808adce/5b6ee869474b4268a5c7982548c69e2e.jpg' style='width:300px;height:auto;object-fit:cover;border:1px solid #ddd;'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56105822-4300-4870-a244-211ce6f2c518",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "So we've shown how to scrape, embed, and search using both text and image items from Zalando. ScrapeGraph-AI is pretty neat - it handles the scraping automatically without needing to mess with selectors. Jina CLIP v2 works really well for combining text and images in the same search space. And Qdrant is solid - fast, easy to use, and that dashboard is actually quite helpful for exploring your data.\n",
    "\n",
    "We could expand this further by scraping more data and implementing a re-ranker to surface results that are truly relevant to the query - but I'll leave that to you! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
